{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilingual Models\n",
    "\n",
    "We distribute new models that are capable of handling text in multiple languages within a singular model. \n",
    "\n",
    "The NER models are trained over 4 languages (English, German, Dutch and Spanish).\n",
    "\n",
    "| ID | Task | Language | Training Dataset | Accuracy | Contributor / Notes |\n",
    "| -------------    | ------------- |------------- |------------- | ------------- | ------------- |\n",
    "| '[ner-multi](https://huggingface.co/flair/ner-multi)' | NER (4-class) | Multilingual | Conll-03   |  **89.27**  (average F1) | (4 languages)\n",
    "| '[ner-multi-fast](https://huggingface.co/flair/ner-multi-fast)' | NER (4-class)|  Multilingual |  Conll-03   |  **87.91**  (average F1) | (4 languages)\n",
    "\n",
    "You can pass text in any of these languages to the model. In particular, the NER also kind of works for languages it was not trained on, such as French."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER MULTI 4-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-16 22:57:26,578 Reading data from C:\\Users\\Bernard\\.flair\\datasets\\conll_03\n",
      "2021-05-16 22:57:26,579 Train: C:\\Users\\Bernard\\.flair\\datasets\\conll_03\\train.txt\n",
      "2021-05-16 22:57:26,580 Dev: C:\\Users\\Bernard\\.flair\\datasets\\conll_03\\dev.txt\n",
      "2021-05-16 22:57:26,580 Test: C:\\Users\\Bernard\\.flair\\datasets\\conll_03\\test.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus, MultiCorpus\n",
    "\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "from flair.datasets import CONLL_03, CONLL_03_GERMAN, CONLL_03_DUTCH, CONLL_03_SPANISH\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "\n",
    "# 1. get the multi-language corpus\n",
    "corpus: Corpus = MultiCorpus([\n",
    "    CONLL_03(),         # English corpus\n",
    "#     CONLL_03_GERMAN(),  # German corpus\n",
    "#     CONLL_03_DUTCH(),   # Dutch corpus\n",
    "#     CONLL_03_SPANISH(), # Spanish corpus\n",
    "    ])\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "\n",
    "# 4. initialize each embedding we use\n",
    "embedding_types = [\n",
    "\n",
    "    # GloVe embeddings\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # FastText embeddings\n",
    "    WordEmbeddings('de'),\n",
    "\n",
    "    # contextual string embeddings, forward\n",
    "    FlairEmbeddings('multi-forward'),\n",
    "\n",
    "    # contextual string embeddings, backward\n",
    "    FlairEmbeddings('multi-backward'),\n",
    "]\n",
    "\n",
    "# embedding stack consists of Flair and GloVe embeddings\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=tag_dictionary,\n",
    "                        tag_type=tag_type )\n",
    "\n",
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-16 22:57:40,717 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 22:57:40,718 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): WordEmbeddings('de')\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(11854, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_3): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(11854, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4496, out_features=4496, bias=True)\n",
      "  (rnn): LSTM(4496, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-05-16 22:57:40,718 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 22:57:40,719 Corpus: \"MultiCorpus: 14987 train + 3466 dev + 3684 test sentences\n",
      " - CONLL_03 Corpus: 14987 train + 3466 dev + 3684 test sentences\"\n",
      "2021-05-16 22:57:40,720 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 22:57:40,720 Parameters:\n",
      "2021-05-16 22:57:40,721  - learning_rate: \"0.1\"\n",
      "2021-05-16 22:57:40,721  - mini_batch_size: \"32\"\n",
      "2021-05-16 22:57:40,722  - patience: \"3\"\n",
      "2021-05-16 22:57:40,722  - anneal_factor: \"0.5\"\n",
      "2021-05-16 22:57:40,723  - max_epochs: \"3\"\n",
      "2021-05-16 22:57:40,723  - shuffle: \"True\"\n",
      "2021-05-16 22:57:40,724  - train_with_dev: \"False\"\n",
      "2021-05-16 22:57:40,724  - batch_growth_annealing: \"False\"\n",
      "2021-05-16 22:57:40,725 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 22:57:40,726 Model training base path: \"resources\\taggers\\ner-multi\"\n",
      "2021-05-16 22:57:40,726 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 22:57:40,727 Device: cuda:0\n",
      "2021-05-16 22:57:40,727 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 22:57:40,728 Embeddings storage mode: cpu\n",
      "2021-05-16 22:57:40,729 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 22:57:57,322 epoch 1 - iter 46/469 - loss 11.87637554 - samples/sec: 88.73 - lr: 0.100000\n",
      "2021-05-16 22:58:12,675 epoch 1 - iter 92/469 - loss 8.84570238 - samples/sec: 95.90 - lr: 0.100000\n",
      "2021-05-16 22:58:27,051 epoch 1 - iter 138/469 - loss 7.33431297 - samples/sec: 102.41 - lr: 0.100000\n",
      "2021-05-16 22:58:41,120 epoch 1 - iter 184/469 - loss 6.27134732 - samples/sec: 104.64 - lr: 0.100000\n",
      "2021-05-16 22:58:55,025 epoch 1 - iter 230/469 - loss 5.57665560 - samples/sec: 105.89 - lr: 0.100000\n",
      "2021-05-16 22:59:11,637 epoch 1 - iter 276/469 - loss 5.18766309 - samples/sec: 88.64 - lr: 0.100000\n",
      "2021-05-16 22:59:27,386 epoch 1 - iter 322/469 - loss 4.86277993 - samples/sec: 93.50 - lr: 0.100000\n",
      "2021-05-16 22:59:43,187 epoch 1 - iter 368/469 - loss 4.61746931 - samples/sec: 93.18 - lr: 0.100000\n",
      "2021-05-16 23:00:01,724 epoch 1 - iter 414/469 - loss 4.41655341 - samples/sec: 79.43 - lr: 0.100000\n",
      "2021-05-16 23:00:19,370 epoch 1 - iter 460/469 - loss 4.20925408 - samples/sec: 83.43 - lr: 0.100000\n",
      "2021-05-16 23:00:22,307 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:00:22,308 EPOCH 1 done: loss 4.1780 - lr 0.1000000\n",
      "2021-05-16 23:00:57,162 DEV : loss 1.6980996131896973 - score 0.8299\n",
      "2021-05-16 23:00:57,383 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-05-16 23:01:07,020 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:01:16,412 epoch 2 - iter 46/469 - loss 2.06844591 - samples/sec: 156.85 - lr: 0.100000\n",
      "2021-05-16 23:01:25,573 epoch 2 - iter 92/469 - loss 2.13581359 - samples/sec: 160.78 - lr: 0.100000\n",
      "2021-05-16 23:01:35,259 epoch 2 - iter 138/469 - loss 2.00223099 - samples/sec: 152.03 - lr: 0.100000\n",
      "2021-05-16 23:01:44,229 epoch 2 - iter 184/469 - loss 1.95531842 - samples/sec: 164.14 - lr: 0.100000\n",
      "2021-05-16 23:01:54,230 epoch 2 - iter 230/469 - loss 1.90051891 - samples/sec: 147.21 - lr: 0.100000\n",
      "2021-05-16 23:02:03,216 epoch 2 - iter 276/469 - loss 1.86673898 - samples/sec: 163.87 - lr: 0.100000\n",
      "2021-05-16 23:02:12,322 epoch 2 - iter 322/469 - loss 1.81233884 - samples/sec: 161.69 - lr: 0.100000\n",
      "2021-05-16 23:02:21,300 epoch 2 - iter 368/469 - loss 1.77345382 - samples/sec: 164.01 - lr: 0.100000\n",
      "2021-05-16 23:02:30,123 epoch 2 - iter 414/469 - loss 1.76224823 - samples/sec: 166.93 - lr: 0.100000\n",
      "2021-05-16 23:02:39,087 epoch 2 - iter 460/469 - loss 1.73640474 - samples/sec: 164.29 - lr: 0.100000\n",
      "2021-05-16 23:02:40,919 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:02:40,920 EPOCH 2 done: loss 1.7327 - lr 0.1000000\n",
      "2021-05-16 23:02:55,010 DEV : loss 0.9827048182487488 - score 0.9053\n",
      "2021-05-16 23:02:55,233 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-05-16 23:03:04,859 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:03:13,812 epoch 3 - iter 46/469 - loss 1.43264117 - samples/sec: 164.47 - lr: 0.100000\n",
      "2021-05-16 23:03:23,062 epoch 3 - iter 92/469 - loss 1.42739347 - samples/sec: 159.17 - lr: 0.100000\n",
      "2021-05-16 23:03:31,927 epoch 3 - iter 138/469 - loss 1.37695340 - samples/sec: 166.12 - lr: 0.100000\n",
      "2021-05-16 23:03:40,809 epoch 3 - iter 184/469 - loss 1.37721635 - samples/sec: 165.80 - lr: 0.100000\n",
      "2021-05-16 23:03:50,344 epoch 3 - iter 230/469 - loss 1.36044525 - samples/sec: 154.46 - lr: 0.100000\n",
      "2021-05-16 23:03:58,873 epoch 3 - iter 276/469 - loss 1.33965645 - samples/sec: 172.63 - lr: 0.100000\n",
      "2021-05-16 23:04:08,245 epoch 3 - iter 322/469 - loss 1.32098487 - samples/sec: 157.10 - lr: 0.100000\n",
      "2021-05-16 23:04:17,004 epoch 3 - iter 368/469 - loss 1.33290436 - samples/sec: 168.13 - lr: 0.100000\n",
      "2021-05-16 23:04:26,123 epoch 3 - iter 414/469 - loss 1.33724730 - samples/sec: 161.45 - lr: 0.100000\n",
      "2021-05-16 23:04:35,278 epoch 3 - iter 460/469 - loss 1.32013706 - samples/sec: 160.85 - lr: 0.100000\n",
      "2021-05-16 23:04:37,186 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:04:37,188 EPOCH 3 done: loss 1.3194 - lr 0.1000000\n",
      "2021-05-16 23:04:51,028 DEV : loss 0.8215925693511963 - score 0.9097\n",
      "2021-05-16 23:04:51,248 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-05-16 23:05:10,557 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:05:10,558 Testing using best model ...\n",
      "2021-05-16 23:05:10,559 loading file resources\\taggers\\ner-multi\\best-model.pt\n",
      "2021-05-16 23:05:34,536 0.8833\t0.8750\t0.8791\n",
      "2021-05-16 23:05:34,537 \n",
      "Results:\n",
      "- F1-score (micro) 0.8791\n",
      "- F1-score (macro) 0.8635\n",
      "\n",
      "By class:\n",
      "LOC        tp: 1493 - fp: 129 - fn: 175 - precision: 0.9205 - recall: 0.8951 - f1-score: 0.9076\n",
      "MISC       tp: 548 - fp: 170 - fn: 154 - precision: 0.7632 - recall: 0.7806 - f1-score: 0.7718\n",
      "ORG        tp: 1350 - fp: 186 - fn: 311 - precision: 0.8789 - recall: 0.8128 - f1-score: 0.8445\n",
      "PER        tp: 1551 - fp: 168 - fn: 66 - precision: 0.9023 - recall: 0.9592 - f1-score: 0.9299\n",
      "2021-05-16 23:05:34,537 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:05:34,538 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-16 23:05:51,642 C:\\Users\\Bernard\\.flair\\datasets\\conll_03\n",
      "2021-05-16 23:05:51,643 0.8833\t0.8750\t0.8791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8791247887574491,\n",
       " 'dev_score_history': [0.8299498643872771,\n",
       "  0.9053001758352173,\n",
       "  0.9096599560142108],\n",
       " 'train_loss_history': [4.178048132960476,\n",
       "  1.7326754077411155,\n",
       "  1.3194100373208142],\n",
       " 'dev_loss_history': [1.6980996131896973,\n",
       "  0.9827048182487488,\n",
       "  0.8215925693511963]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. run training\n",
    "trainer.train('resources/taggers/ner-multi',\n",
    "              train_with_dev=False,\n",
    "              max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
