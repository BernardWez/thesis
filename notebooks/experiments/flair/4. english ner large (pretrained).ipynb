{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '1. english ner (pretrained).ipynb',\n",
       " '2. multi ner (pre-trained).ipynb',\n",
       " '3. dutch ner large (pre-trained) .ipynb',\n",
       " '4. english ner large (pretrained).ipynb',\n",
       " 'outcomes-flair-ner-dutch-large-DutchPolicyDocs',\n",
       " 'outcomes-flair-ner-dutch-large-GWN',\n",
       " 'outcomes-flair-ner-dutch-large-LGL',\n",
       " 'outcomes-flair-ner-english-DutchPolicyDocs',\n",
       " 'outcomes-flair-ner-english-GWN',\n",
       " 'outcomes-flair-ner-english-large-DutchPolicyDocs',\n",
       " 'outcomes-flair-ner-english-large-GWN',\n",
       " 'outcomes-flair-ner-english-large-LGL',\n",
       " 'outcomes-flair-ner-english-large-TR-News',\n",
       " 'outcomes-flair-ner-english-LGL',\n",
       " 'outcomes-flair-ner-english-TR-News',\n",
       " 'outcomes-flair-ner-multi-DutchPolicyDocs',\n",
       " 'outcomes-flair-ner-multi-GWN',\n",
       " 'outcomes-flair-ner-multi-LGL',\n",
       " 'outcomes-flair-ner-multi-TR-News',\n",
       " 'xxx. dutch ner (pre-trained).ipynb',\n",
       " 'xxx. multi fast ner (pre-trained).ipynbl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir():\n",
    "    if 'outcomes' in i:\n",
    "        os.rename(i, i + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Het systeem kan het opgegeven bestand niet vinden: 'xxx. multi fast ner (pre-trained).ipynb' -> 'xxx. multi fast ner (pre-trained).ipynbhellooo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-90c4d8bda190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'hellooo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Het systeem kan het opgegeven bestand niet vinden: 'xxx. multi fast ner (pre-trained).ipynb' -> 'xxx. multi fast ner (pre-trained).ipynbhellooo'"
     ]
    }
   ],
   "source": [
    "os.rename(i, i+'hellooo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxx. multi fast ner (pre-trained).ipynb'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Insert utils folder into path\n",
    "sys.path.insert(1, '../utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 15:48:59,667 loading file C:\\Users\\Bernard\\.flair\\models\\ner-english-large\\07301f59bb8cb113803be316267f06ddf9243cdbba92a4c8067ef92442d2c574.554244d3476d97501a766a98078421817b14654496b86f2f7bd139dc502a4f29\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "model_name = 'flair/ner-english-large'\n",
    "filtered = False\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DutchPolicyDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../../data/DutchPolicyDocs/DutchPolicyDocs.json' \n",
    "dataset = 'DutchPolicyDocs'\n",
    "\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_all_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for DutchPolicyDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1044/1044 [00:32<00:00, 32.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import flair_predictions\n",
    "\n",
    "processed_predictions_all = flair_predictions.make_predictions(data_all_toponyms, tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results DutchPolicyDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 1953 | tp: 3624 | fn: 1919\n",
      "precision: 0.650 | recall: 0.654 | f-score: 0.652 | accuracy: 0.654\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 1667 | tp: 3910 | fn: 1633\n",
      "precision: 0.701 | recall: 0.705 | f-score: 0.703 | accuracy: 0.705\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# All toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_all_toponyms, processed_predictions_all,\n",
    "                                      model_name=model_name, dataset=dataset, filtered=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TR-News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file path TR-News dataset\n",
    "file_path = '../../../data/TR-News/TR-News.xml'\n",
    "dataset = 'TR-News'\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_all_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=True, word_limit=1800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for TR-News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 184/184 [00:11<00:00, 15.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import flair_predictions\n",
    "\n",
    "processed_predictions_all = flair_predictions.make_predictions(data_all_toponyms, tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results TR-News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 102 | tp: 1004 | fn: 314\n",
      "precision: 0.908 | recall: 0.762 | f-score: 0.828 | accuracy: 0.762\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 64 | tp: 1042 | fn: 276\n",
      "precision: 0.942 | recall: 0.791 | f-score: 0.860 | accuracy: 0.791\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# All toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_all_toponyms, processed_predictions_all,\n",
    "                                     model_name=model_name, dataset=dataset, filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file path LGL dataset\n",
    "file_path = '../../../data/LGL/LGL.xml'\n",
    "dataset = 'LGL'\n",
    "\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_all_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=True, word_limit=1700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for LGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 970/970 [00:58<00:00, 16.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import flair_predictions\n",
    "\n",
    "processed_predictions_all = flair_predictions.make_predictions(data_all_toponyms, tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results LGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 871 | tp: 3537 | fn: 1551\n",
      "precision: 0.802 | recall: 0.695 | f-score: 0.745 | accuracy: 0.695\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 591 | tp: 3817 | fn: 1271\n",
      "precision: 0.866 | recall: 0.750 | f-score: 0.804 | accuracy: 0.750\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# All toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_all_toponyms, processed_predictions_all,\n",
    "                                      model_name=model_name, dataset=dataset, filtered=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoWebNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file path GWN dataset\n",
    "file_path = '../../../data/GeoWebNews/GeoWebNews.xml'\n",
    "dataset = 'GWN'\n",
    "filtered = True\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_filtered_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=True, word_limit=1700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for GWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 396/396 [00:25<00:00, 15.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import flair_predictions\n",
    "\n",
    "processed_predictions_filtered = flair_predictions.make_predictions(data_filtered_toponyms, tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results GWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 114 | tp: 1698 | fn: 900\n",
      "precision: 0.937 | recall: 0.654 | f-score: 0.770 | accuracy: 0.654\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 90 | tp: 1722 | fn: 876\n",
      "precision: 0.950 | recall: 0.663 | f-score: 0.781 | accuracy: 0.663\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Filtered toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_filtered_toponyms, processed_predictions_filtered,\n",
    "                                      model_name=model_name, dataset=dataset, filtered=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flair",
   "language": "python",
   "name": "flair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
