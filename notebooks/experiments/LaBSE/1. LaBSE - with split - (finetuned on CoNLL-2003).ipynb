{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41086466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Insert utils folder into path\n",
    "sys.path.insert(1, '../utils')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7b115",
   "metadata": {},
   "source": [
    "## Loading Fine-tuned LaBSE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1681b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/LaBSE-fine-tuned-conll-2003'\n",
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "split = True\n",
    "\n",
    "model_name = 'LaBSE'\n",
    "filtered = False\n",
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac507f",
   "metadata": {},
   "source": [
    "### DutchPolicyDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc88b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../../data/DutchPolicyDocs/DutchPolicyDocs.json'\n",
    "dataset = 'DutchPolicyDocs'\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_all_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dceff1",
   "metadata": {},
   "source": [
    "### Processing the data for Huggingface Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca7e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1632904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4348c7bc357f4c33a2bf6775dffe7919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import preparing_dataset\n",
    "\n",
    "DPD = preparing_dataset.prepare_dataset(data_all_toponyms, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45a604",
   "metadata": {},
   "source": [
    "### Prepare evaluation trainer for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5997ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "test_trainer = Trainer(model, \n",
    "                       data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59490f02",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d255e503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [131/131 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "raw_pred, _, _ = test_trainer.predict(DPD)\n",
    "predictions = np.argmax(raw_pred, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3cdedd",
   "metadata": {},
   "source": [
    "### Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1445581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_predictions\n",
    "\n",
    "processed_results = process_predictions.process_predictions(predictions, DPD, label_list, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af9cb0",
   "metadata": {},
   "source": [
    "### Evaluation DPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f80ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 2904 | tp: 3346 | fn: 2197\n",
      "precision: 0.535 | recall: 0.604 | f-score: 0.567 | accuracy: 0.604\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 2625 | tp: 3625 | fn: 1919\n",
      "precision: 0.580 | recall: 0.654 | f-score: 0.615 | accuracy: 0.654\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# All toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_all_toponyms, processed_results,\n",
    "                                      model_name=model_name, dataset=dataset, filtered=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1fb15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812894c",
   "metadata": {},
   "source": [
    "## TR-News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d3ad6",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8de81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file path TR-News dataset\n",
    "file_path = '../../../data/TR-News/TR-News.xml'\n",
    "dataset = 'TR-News'\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_all_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654b6c9",
   "metadata": {},
   "source": [
    "### Processing the data for Huggingface Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd45c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b26c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28561a05ba64f1fab85e0b87416b2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import preparing_dataset\n",
    "\n",
    "TRN = preparing_dataset.prepare_dataset(data_all_toponyms, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aed20d",
   "metadata": {},
   "source": [
    "### Prepare evaluation trainer for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9088989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "test_trainer = Trainer(model, \n",
    "                       data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74314bc",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79a8e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "raw_pred, _, _ = test_trainer.predict(TRN)\n",
    "predictions = np.argmax(raw_pred, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ea6c1",
   "metadata": {},
   "source": [
    "### Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ece8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_predictions\n",
    "\n",
    "processed_results = process_predictions.process_predictions(predictions, TRN, label_list, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb24aa",
   "metadata": {},
   "source": [
    "### Evaluation TR-News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74f5812b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 328 | tp: 977 | fn: 341\n",
      "precision: 0.749 | recall: 0.741 | f-score: 0.745 | accuracy: 0.741\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 275 | tp: 1030 | fn: 288\n",
      "precision: 0.789 | recall: 0.781 | f-score: 0.785 | accuracy: 0.781\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# All toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_all_toponyms, processed_results,\n",
    "                                      model_name=model_name, dataset=dataset, filtered=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96dd398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5ae33",
   "metadata": {},
   "source": [
    "## LGL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3238f5",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "989b0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file path LGL dataset\n",
    "file_path = '../../../data/LGL/LGL.xml'\n",
    "dataset = 'LGL'\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_all_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec984f",
   "metadata": {},
   "source": [
    "### Processing the data for Huggingface Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38a3459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e253e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd7c0e3f41b475fbf68d4894b4edcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import preparing_dataset\n",
    "\n",
    "LGL = preparing_dataset.prepare_dataset(data_all_toponyms, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63eabb",
   "metadata": {},
   "source": [
    "### Prepare evaluation trainer for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4449bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "test_trainer = Trainer(model, \n",
    "                       data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d45939b",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5ca6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='111' max='111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [111/111 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "raw_pred, _, _ = test_trainer.predict(LGL)\n",
    "predictions = np.argmax(raw_pred, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032646f",
   "metadata": {},
   "source": [
    "### Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3839969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_predictions\n",
    "\n",
    "processed_results = process_predictions.process_predictions(predictions, LGL, label_list, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ebc6a",
   "metadata": {},
   "source": [
    "### Evaluation LGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f34d61fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 1915 | tp: 3381 | fn: 1707\n",
      "precision: 0.638 | recall: 0.665 | f-score: 0.651 | accuracy: 0.665\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 1534 | tp: 3762 | fn: 1333\n",
      "precision: 0.710 | recall: 0.738 | f-score: 0.724 | accuracy: 0.739\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# All toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_all_toponyms, processed_results,\n",
    "                                      model_name=model_name, dataset=dataset, filtered=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c781c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9fd95",
   "metadata": {},
   "source": [
    "## GeoWebNews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616c6a0",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c787c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file path GWN dataset\n",
    "file_path = '../../../data/GeoWebNews/GeoWebNews.xml'\n",
    "dataset = 'GWN'\n",
    "filtered = True\n",
    "\n",
    "import loading_functions\n",
    "\n",
    "data_filtered_toponyms = loading_functions.prepare_data(file_path, filtered=filtered, split=split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d0bba",
   "metadata": {},
   "source": [
    "### Processing the data for Huggingface Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a9fc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bee9561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e70d9b68e34f92810f752f2224ca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import preparing_dataset\n",
    "\n",
    "GWN_filtered = preparing_dataset.prepare_dataset(data_filtered_toponyms, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac4292",
   "metadata": {},
   "source": [
    "### Prepare evaluation trainer for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "731d741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "test_trainer = Trainer(model, \n",
    "                       data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9cc6bb",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "079b78b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "raw_pred_filtered, _, _ = test_trainer.predict(GWN_filtered)\n",
    "predictions_filtered = np.argmax(raw_pred_filtered, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887c74a",
   "metadata": {},
   "source": [
    "### Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18b78be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_predictions\n",
    "\n",
    "processed_predictions_filtered = process_predictions.process_predictions(predictions_filtered, GWN_filtered, label_list, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81160c83",
   "metadata": {},
   "source": [
    "### Evaluation GWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd3baa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation mode: strict\n",
      "fp: 523 | tp: 1640 | fn: 958\n",
      "precision: 0.758 | recall: 0.631 | f-score: 0.689 | accuracy: 0.631\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "Evaluation mode: forgiving\n",
      "fp: 462 | tp: 1701 | fn: 897\n",
      "precision: 0.786 | recall: 0.655 | f-score: 0.715 | accuracy: 0.655\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "# Filtered toponyms\n",
    "strict, forgiving = evaluate.evaluate(data_filtered_toponyms, processed_predictions_filtered,\n",
    "                                      model_name=model_name, dataset=dataset, filtered=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4922bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes\n",
    "\n",
    "import store_outcomes\n",
    "\n",
    "store_outcomes.store_outcome(model_name, dataset, strict, forgiving)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
