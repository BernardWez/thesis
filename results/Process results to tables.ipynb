{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1cfbbb",
   "metadata": {},
   "source": [
    "## Create empty results file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28676151",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'dataset', 'mode', 'filtered', \n",
    "                           'precision', 'recall', 'f1', 'acc'])\n",
    "```\n",
    "\n",
    "```python\n",
    "df.to_pickle(\"results.pkl\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d72c3",
   "metadata": {},
   "source": [
    "## Latest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e6a9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mode</th>\n",
       "      <th>filtered</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flair/ner-english</td>\n",
       "      <td>DutchPolicyDocs</td>\n",
       "      <td>strict</td>\n",
       "      <td>False</td>\n",
       "      <td>0.738226</td>\n",
       "      <td>0.243190</td>\n",
       "      <td>0.365857</td>\n",
       "      <td>0.243190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flair/ner-english</td>\n",
       "      <td>DutchPolicyDocs</td>\n",
       "      <td>forgiving</td>\n",
       "      <td>False</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.292806</td>\n",
       "      <td>0.440834</td>\n",
       "      <td>0.293704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flair/ner-english</td>\n",
       "      <td>TR-News</td>\n",
       "      <td>strict</td>\n",
       "      <td>False</td>\n",
       "      <td>0.885305</td>\n",
       "      <td>0.749052</td>\n",
       "      <td>0.811499</td>\n",
       "      <td>0.749052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flair/ner-english</td>\n",
       "      <td>TR-News</td>\n",
       "      <td>forgiving</td>\n",
       "      <td>False</td>\n",
       "      <td>0.924731</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.847291</td>\n",
       "      <td>0.782411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flair/ner-english</td>\n",
       "      <td>LGL</td>\n",
       "      <td>strict</td>\n",
       "      <td>False</td>\n",
       "      <td>0.787641</td>\n",
       "      <td>0.671384</td>\n",
       "      <td>0.724881</td>\n",
       "      <td>0.671384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>XLM-R-ner</td>\n",
       "      <td>TR-News</td>\n",
       "      <td>forgiving</td>\n",
       "      <td>False</td>\n",
       "      <td>0.958378</td>\n",
       "      <td>0.676205</td>\n",
       "      <td>0.792936</td>\n",
       "      <td>0.681335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>XLM-R-ner</td>\n",
       "      <td>LGL</td>\n",
       "      <td>strict</td>\n",
       "      <td>False</td>\n",
       "      <td>0.756106</td>\n",
       "      <td>0.444182</td>\n",
       "      <td>0.559614</td>\n",
       "      <td>0.444182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>XLM-R-ner</td>\n",
       "      <td>LGL</td>\n",
       "      <td>forgiving</td>\n",
       "      <td>False</td>\n",
       "      <td>0.946136</td>\n",
       "      <td>0.551267</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.555818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>XLM-R-ner</td>\n",
       "      <td>GWN</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>0.833561</td>\n",
       "      <td>0.470362</td>\n",
       "      <td>0.601378</td>\n",
       "      <td>0.470362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>XLM-R-ner</td>\n",
       "      <td>GWN</td>\n",
       "      <td>forgiving</td>\n",
       "      <td>True</td>\n",
       "      <td>0.959754</td>\n",
       "      <td>0.537844</td>\n",
       "      <td>0.689368</td>\n",
       "      <td>0.541570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model          dataset       mode filtered  precision  \\\n",
       "0   flair/ner-english  DutchPolicyDocs     strict    False   0.738226   \n",
       "1   flair/ner-english  DutchPolicyDocs  forgiving    False   0.891566   \n",
       "2   flair/ner-english          TR-News     strict    False   0.885305   \n",
       "3   flair/ner-english          TR-News  forgiving    False   0.924731   \n",
       "4   flair/ner-english              LGL     strict    False   0.787641   \n",
       "..                ...              ...        ...      ...        ...   \n",
       "75          XLM-R-ner          TR-News  forgiving    False   0.958378   \n",
       "76          XLM-R-ner              LGL     strict    False   0.756106   \n",
       "77          XLM-R-ner              LGL  forgiving    False   0.946136   \n",
       "78          XLM-R-ner              GWN     strict     True   0.833561   \n",
       "79          XLM-R-ner              GWN  forgiving     True   0.959754   \n",
       "\n",
       "      recall        f1       acc  \n",
       "0   0.243190  0.365857  0.243190  \n",
       "1   0.292806  0.440834  0.293704  \n",
       "2   0.749052  0.811499  0.749052  \n",
       "3   0.781818  0.847291  0.782411  \n",
       "4   0.671384  0.724881  0.671384  \n",
       "..       ...       ...       ...  \n",
       "75  0.676205  0.792936  0.681335  \n",
       "76  0.444182  0.559614  0.444182  \n",
       "77  0.551267  0.696638  0.555818  \n",
       "78  0.470362  0.601378  0.470362  \n",
       "79  0.537844  0.689368  0.541570  \n",
       "\n",
       "[80 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_pickle('results.pkl')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb5b72",
   "metadata": {},
   "source": [
    "## Table 1: f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df791c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f = results[results['mode'] == 'forgiving'].sort_values(['model', 'dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece0c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scores_combined = []\n",
    "\n",
    "for idx, row in results.groupby(['model', 'dataset']):\n",
    "    \n",
    "    f_scores_combined.append(row.iloc[0]['f1'].round(3).astype(str) + ' (' + row.iloc[1]['f1'].round(3).astype(str) + ')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc228311",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f['f1-combined'] = f_scores_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f6e401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>DutchPolicyDocs</th>\n",
       "      <th>GWN</th>\n",
       "      <th>LGL</th>\n",
       "      <th>TR-News</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LaBSE</th>\n",
       "      <td>0.766 (0.951)</td>\n",
       "      <td>0.689 (0.82)</td>\n",
       "      <td>0.651 (0.807)</td>\n",
       "      <td>0.745 (0.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLM-R-ner</th>\n",
       "      <td>0.624 (0.765)</td>\n",
       "      <td>0.601 (0.689)</td>\n",
       "      <td>0.56 (0.697)</td>\n",
       "      <td>0.669 (0.793)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_core_web_lg</th>\n",
       "      <td>0.187 (0.262)</td>\n",
       "      <td>0.56 (0.719)</td>\n",
       "      <td>0.498 (0.706)</td>\n",
       "      <td>0.697 (0.813)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_core_web_trf</th>\n",
       "      <td>0.477 (0.572)</td>\n",
       "      <td>0.587 (0.75)</td>\n",
       "      <td>0.556 (0.774)</td>\n",
       "      <td>0.718 (0.842)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-dutch-large</th>\n",
       "      <td>0.866 (0.948)</td>\n",
       "      <td>0.737 (0.758)</td>\n",
       "      <td>0.69 (0.759)</td>\n",
       "      <td>0.775 (0.816)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-english</th>\n",
       "      <td>0.366 (0.441)</td>\n",
       "      <td>0.752 (0.771)</td>\n",
       "      <td>0.725 (0.793)</td>\n",
       "      <td>0.811 (0.847)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-english-large</th>\n",
       "      <td>0.88 (0.959)</td>\n",
       "      <td>0.77 (0.788)</td>\n",
       "      <td>0.745 (0.815)</td>\n",
       "      <td>0.828 (0.873)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-multi</th>\n",
       "      <td>0.788 (0.886)</td>\n",
       "      <td>0.744 (0.77)</td>\n",
       "      <td>0.696 (0.769)</td>\n",
       "      <td>0.801 (0.844)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mBERT</th>\n",
       "      <td>0.728 (0.937)</td>\n",
       "      <td>0.681 (0.799)</td>\n",
       "      <td>0.642 (0.793)</td>\n",
       "      <td>0.739 (0.857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_core_news_lg</th>\n",
       "      <td>0.64 (0.773)</td>\n",
       "      <td>0.366 (0.454)</td>\n",
       "      <td>0.327 (0.428)</td>\n",
       "      <td>0.504 (0.584)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                 DutchPolicyDocs            GWN            LGL  \\\n",
       "model                                                                   \n",
       "LaBSE                     0.766 (0.951)   0.689 (0.82)  0.651 (0.807)   \n",
       "XLM-R-ner                 0.624 (0.765)  0.601 (0.689)   0.56 (0.697)   \n",
       "en_core_web_lg            0.187 (0.262)   0.56 (0.719)  0.498 (0.706)   \n",
       "en_core_web_trf           0.477 (0.572)   0.587 (0.75)  0.556 (0.774)   \n",
       "flair/ner-dutch-large     0.866 (0.948)  0.737 (0.758)   0.69 (0.759)   \n",
       "flair/ner-english         0.366 (0.441)  0.752 (0.771)  0.725 (0.793)   \n",
       "flair/ner-english-large    0.88 (0.959)   0.77 (0.788)  0.745 (0.815)   \n",
       "flair/ner-multi           0.788 (0.886)   0.744 (0.77)  0.696 (0.769)   \n",
       "mBERT                     0.728 (0.937)  0.681 (0.799)  0.642 (0.793)   \n",
       "nl_core_news_lg            0.64 (0.773)  0.366 (0.454)  0.327 (0.428)   \n",
       "\n",
       "dataset                        TR-News  \n",
       "model                                   \n",
       "LaBSE                    0.745 (0.871)  \n",
       "XLM-R-ner                0.669 (0.793)  \n",
       "en_core_web_lg           0.697 (0.813)  \n",
       "en_core_web_trf          0.718 (0.842)  \n",
       "flair/ner-dutch-large    0.775 (0.816)  \n",
       "flair/ner-english        0.811 (0.847)  \n",
       "flair/ner-english-large  0.828 (0.873)  \n",
       "flair/ner-multi          0.801 (0.844)  \n",
       "mBERT                    0.739 (0.857)  \n",
       "nl_core_news_lg          0.504 (0.584)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(results_f, values='f1-combined', index=['model'], columns=['dataset'], aggfunc=lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300728ac",
   "metadata": {},
   "source": [
    "### Add EUPEG results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132bdaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GeoWebNews</th>\n",
       "      <th>LGL</th>\n",
       "      <th>TR-News</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoparser</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DM_NLP+Pop</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StanfordNER</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UniMelb+Pop</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset      GeoWebNews    LGL  TR-News\n",
       "geoparser                              \n",
       "DM_NLP+Pop        0.717  0.677    0.677\n",
       "StanfordNER       0.739  0.677    0.803\n",
       "UniMelb+Pop       0.722  0.673    0.715"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eupeg_results = pd.read_excel('geoparsing-results-EUPEG.xlsx')\n",
    "\n",
    "eupeg_subset = eupeg_results[(eupeg_results['dataset'].isin(['LGL', 'TR-News', 'GeoWebNews'])) &\n",
    "                             (eupeg_results['geoparser'].isin(['StanfordNER', 'DM_NLP+Pop', 'UniMelb+Pop']))]\n",
    "\n",
    "pd.pivot_table(eupeg_subset, values='f-score', index='geoparser', columns='dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cb66c",
   "metadata": {},
   "source": [
    "## Table 2: averaged metrics on English corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26c6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_english_corpora = results[results['dataset'] != 'DutchPolicyDocs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae4c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_english_corpora_s = results_english_corpora[results_english_corpora['mode'] == 'strict']\n",
    "results_english_corpora_f = results_english_corpora[results_english_corpora['mode'] == 'forgiving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe145d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_avg_s = results_english_corpora_s.groupby('model').mean().round(3).rename(columns={'precision': 'precision_s','recall': 'recall_s','f1': 'f1_s', 'acc': 'acc_s'})\n",
    "\n",
    "model_metrics_avg_f = results_english_corpora_f.groupby('model').mean().round(3).rename(columns={'precision': 'precision_f','recall': 'recall_f','f1': 'f1_f', 'acc': 'acc_f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6c1eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LaBSE</th>\n",
       "      <td>0.715 (0.897)</td>\n",
       "      <td>0.679 (0.78)</td>\n",
       "      <td>0.695 (0.833)</td>\n",
       "      <td>0.679 (0.853)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLM-R-ner</th>\n",
       "      <td>0.798 (0.955)</td>\n",
       "      <td>0.496 (0.588)</td>\n",
       "      <td>0.61 (0.726)</td>\n",
       "      <td>0.496 (0.593)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_core_web_lg</th>\n",
       "      <td>0.725 (0.927)</td>\n",
       "      <td>0.492 (0.626)</td>\n",
       "      <td>0.585 (0.746)</td>\n",
       "      <td>0.492 (0.627)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en_core_web_trf</th>\n",
       "      <td>0.759 (0.967)</td>\n",
       "      <td>0.526 (0.668)</td>\n",
       "      <td>0.62 (0.789)</td>\n",
       "      <td>0.526 (0.669)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-dutch-large</th>\n",
       "      <td>0.865 (0.917)</td>\n",
       "      <td>0.639 (0.678)</td>\n",
       "      <td>0.734 (0.778)</td>\n",
       "      <td>0.639 (0.679)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-english</th>\n",
       "      <td>0.862 (0.909)</td>\n",
       "      <td>0.686 (0.723)</td>\n",
       "      <td>0.763 (0.804)</td>\n",
       "      <td>0.686 (0.724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-english-large</th>\n",
       "      <td>0.882 (0.932)</td>\n",
       "      <td>0.704 (0.744)</td>\n",
       "      <td>0.781 (0.825)</td>\n",
       "      <td>0.704 (0.744)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-multi</th>\n",
       "      <td>0.838 (0.892)</td>\n",
       "      <td>0.677 (0.72)</td>\n",
       "      <td>0.747 (0.795)</td>\n",
       "      <td>0.677 (0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mBERT</th>\n",
       "      <td>0.724 (0.898)</td>\n",
       "      <td>0.658 (0.752)</td>\n",
       "      <td>0.687 (0.816)</td>\n",
       "      <td>0.658 (0.817)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_core_news_lg</th>\n",
       "      <td>0.637 (0.784)</td>\n",
       "      <td>0.292 (0.357)</td>\n",
       "      <td>0.399 (0.489)</td>\n",
       "      <td>0.292 (0.357)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         avg_precision     avg_recall         avg_f1  \\\n",
       "model                                                                  \n",
       "LaBSE                    0.715 (0.897)   0.679 (0.78)  0.695 (0.833)   \n",
       "XLM-R-ner                0.798 (0.955)  0.496 (0.588)   0.61 (0.726)   \n",
       "en_core_web_lg           0.725 (0.927)  0.492 (0.626)  0.585 (0.746)   \n",
       "en_core_web_trf          0.759 (0.967)  0.526 (0.668)   0.62 (0.789)   \n",
       "flair/ner-dutch-large    0.865 (0.917)  0.639 (0.678)  0.734 (0.778)   \n",
       "flair/ner-english        0.862 (0.909)  0.686 (0.723)  0.763 (0.804)   \n",
       "flair/ner-english-large  0.882 (0.932)  0.704 (0.744)  0.781 (0.825)   \n",
       "flair/ner-multi          0.838 (0.892)   0.677 (0.72)  0.747 (0.795)   \n",
       "mBERT                    0.724 (0.898)  0.658 (0.752)  0.687 (0.816)   \n",
       "nl_core_news_lg          0.637 (0.784)  0.292 (0.357)  0.399 (0.489)   \n",
       "\n",
       "                               avg_acc  \n",
       "model                                   \n",
       "LaBSE                    0.679 (0.853)  \n",
       "XLM-R-ner                0.496 (0.593)  \n",
       "en_core_web_lg           0.492 (0.627)  \n",
       "en_core_web_trf          0.526 (0.669)  \n",
       "flair/ner-dutch-large    0.639 (0.679)  \n",
       "flair/ner-english        0.686 (0.724)  \n",
       "flair/ner-english-large  0.704 (0.744)  \n",
       "flair/ner-multi          0.677 (0.722)  \n",
       "mBERT                    0.658 (0.817)  \n",
       "nl_core_news_lg          0.292 (0.357)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.concat([model_metrics_avg_s, model_metrics_avg_f], axis=1)\n",
    "\n",
    "tmp['avg_precision'] = tmp['precision_s'].astype(str) + ' (' + tmp['precision_f'].astype(str) + ')' \n",
    "\n",
    "tmp['avg_recall'] = tmp['recall_s'].astype(str) + ' (' + tmp['recall_f'].astype(str) + ')' \n",
    "\n",
    "tmp['avg_f1'] = tmp['f1_s'].astype(str) + ' (' + tmp['f1_f'].astype(str) + ')' \n",
    "\n",
    "tmp['avg_acc'] = tmp['acc_s'].astype(str) + ' (' + tmp['acc_f'].astype(str) + ')' \n",
    "\n",
    "tmp = tmp[['avg_precision', 'avg_recall', 'avg_f1', 'avg_acc']]\n",
    "tmp\n",
    "\n",
    "# tmp.to_excel('models-avg-metrics.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac083f19",
   "metadata": {},
   "source": [
    "#### combine with EUPEG results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de106591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f-score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoparser</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DM_NLP+Pop</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.690</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StanfordNER</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UniMelb+Pop</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.703</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision  recall  f-score  accuracy\n",
       "geoparser                                        \n",
       "DM_NLP+Pop       0.781   0.620    0.690       NaN\n",
       "StanfordNER      0.840   0.663    0.740     0.663\n",
       "UniMelb+Pop      0.796   0.634    0.703       NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eupeg_results = pd.read_excel('geoparsing-results-EUPEG.xlsx')\n",
    "eupeg_subset = eupeg_results[(eupeg_results['dataset'].isin(['LGL', 'TR-News', 'GeoWebNews'])) &\n",
    "                             (eupeg_results['geoparser'].isin(['StanfordNER', 'DM_NLP+Pop', 'UniMelb+Pop']))]\n",
    "\n",
    "eupeg_subset.groupby('geoparser').mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df97ef24",
   "metadata": {},
   "source": [
    "## Table 3: model metrics on DPD corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5360279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DPD = results[results['dataset'] == 'DutchPolicyDocs']\n",
    "\n",
    "results_DPD = results_DPD[results_DPD['model'].isin(['LaBSE', \n",
    "                                              'XLM-R-ner',\n",
    "                                              'flair/ner-multi',\n",
    "                                              'flair/ner-dutch-large', \n",
    "                                              'flair/ner-english-large', \n",
    "                                              'mBERT', \n",
    "                                              'nl_core_news_lg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca10fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DPD_s = results_DPD[results_DPD['mode'] == 'strict']\n",
    "results_DPD_f = results_DPD[results_DPD['mode'] == 'forgiving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c79639",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_avg_s = results_DPD_s.groupby('model').mean().round(3).rename(columns={'precision': 'precision_s','recall': 'recall_s','f1': 'f1_s', 'acc': 'acc_s'})\n",
    "\n",
    "model_metrics_avg_f = results_DPD_f.groupby('model').mean().round(3).rename(columns={'precision': 'precision_f','recall': 'recall_f','f1': 'f1_f', 'acc': 'acc_f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73cf3f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LaBSE</th>\n",
       "      <td>0.723 (0.946)</td>\n",
       "      <td>0.815 (0.956)</td>\n",
       "      <td>0.766 (0.951)</td>\n",
       "      <td>0.815 (1.067)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLM-R-ner</th>\n",
       "      <td>0.765 (0.951)</td>\n",
       "      <td>0.527 (0.64)</td>\n",
       "      <td>0.624 (0.765)</td>\n",
       "      <td>0.527 (0.655)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-dutch-large</th>\n",
       "      <td>0.87 (0.958)</td>\n",
       "      <td>0.861 (0.938)</td>\n",
       "      <td>0.866 (0.948)</td>\n",
       "      <td>0.861 (0.948)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-english-large</th>\n",
       "      <td>0.878 (0.96)</td>\n",
       "      <td>0.883 (0.958)</td>\n",
       "      <td>0.88 (0.959)</td>\n",
       "      <td>0.883 (0.966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair/ner-multi</th>\n",
       "      <td>0.837 (0.948)</td>\n",
       "      <td>0.745 (0.831)</td>\n",
       "      <td>0.788 (0.886)</td>\n",
       "      <td>0.745 (0.844)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mBERT</th>\n",
       "      <td>0.693 (0.942)</td>\n",
       "      <td>0.766 (0.932)</td>\n",
       "      <td>0.728 (0.937)</td>\n",
       "      <td>0.766 (1.042)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl_core_news_lg</th>\n",
       "      <td>0.794 (0.963)</td>\n",
       "      <td>0.537 (0.645)</td>\n",
       "      <td>0.64 (0.773)</td>\n",
       "      <td>0.537 (0.651)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             precision         recall             f1  \\\n",
       "model                                                                  \n",
       "LaBSE                    0.723 (0.946)  0.815 (0.956)  0.766 (0.951)   \n",
       "XLM-R-ner                0.765 (0.951)   0.527 (0.64)  0.624 (0.765)   \n",
       "flair/ner-dutch-large     0.87 (0.958)  0.861 (0.938)  0.866 (0.948)   \n",
       "flair/ner-english-large   0.878 (0.96)  0.883 (0.958)   0.88 (0.959)   \n",
       "flair/ner-multi          0.837 (0.948)  0.745 (0.831)  0.788 (0.886)   \n",
       "mBERT                    0.693 (0.942)  0.766 (0.932)  0.728 (0.937)   \n",
       "nl_core_news_lg          0.794 (0.963)  0.537 (0.645)   0.64 (0.773)   \n",
       "\n",
       "                                   acc  \n",
       "model                                   \n",
       "LaBSE                    0.815 (1.067)  \n",
       "XLM-R-ner                0.527 (0.655)  \n",
       "flair/ner-dutch-large    0.861 (0.948)  \n",
       "flair/ner-english-large  0.883 (0.966)  \n",
       "flair/ner-multi          0.745 (0.844)  \n",
       "mBERT                    0.766 (1.042)  \n",
       "nl_core_news_lg          0.537 (0.651)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.concat([model_metrics_avg_s, model_metrics_avg_f], axis=1)\n",
    "\n",
    "tmp['precision'] = tmp['precision_s'].astype(str) + ' (' + tmp['precision_f'].astype(str) + ')' \n",
    "\n",
    "tmp['recall'] = tmp['recall_s'].astype(str) + ' (' + tmp['recall_f'].astype(str) + ')' \n",
    "\n",
    "tmp['f1'] = tmp['f1_s'].astype(str) + ' (' + tmp['f1_f'].astype(str) + ')' \n",
    "\n",
    "tmp['acc'] = tmp['acc_s'].astype(str) + ' (' + tmp['acc_f'].astype(str) + ')' \n",
    "\n",
    "tmp = tmp[['precision', 'recall', 'f1', 'acc']]\n",
    "tmp\n",
    "\n",
    "# tmp.to_excel('models-avg-metrics.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8ac7c",
   "metadata": {},
   "source": [
    "## Table 4: average metrics per corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33a510f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_s = results[results['mode'] == 'strict']\n",
    "results_f = results[results['mode'] == 'forgiving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e13e024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics_s = results_s.groupby('dataset').mean().round(3).rename(columns={'precision': 'precision_s','recall': 'recall_s','f1': 'f1_s', 'acc': 'acc_s'})\n",
    "\n",
    "dataset_metrics_f = results_f.groupby('dataset').mean().round(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b5addb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DutchPolicyDocs</th>\n",
       "      <td>0.767 (0.932)</td>\n",
       "      <td>0.583 (0.676)</td>\n",
       "      <td>0.632 (0.749)</td>\n",
       "      <td>0.583 (0.703)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GWN</th>\n",
       "      <td>0.818 (0.936)</td>\n",
       "      <td>0.543 (0.606)</td>\n",
       "      <td>0.649 (0.732)</td>\n",
       "      <td>0.543 (0.621)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGL</th>\n",
       "      <td>0.701 (0.859)</td>\n",
       "      <td>0.55 (0.654)</td>\n",
       "      <td>0.609 (0.734)</td>\n",
       "      <td>0.55 (0.668)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TR-News</th>\n",
       "      <td>0.823 (0.929)</td>\n",
       "      <td>0.661 (0.73)</td>\n",
       "      <td>0.729 (0.814)</td>\n",
       "      <td>0.661 (0.746)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 avg_precision     avg_recall         avg_f1        avg_acc\n",
       "dataset                                                                    \n",
       "DutchPolicyDocs  0.767 (0.932)  0.583 (0.676)  0.632 (0.749)  0.583 (0.703)\n",
       "GWN              0.818 (0.936)  0.543 (0.606)  0.649 (0.732)  0.543 (0.621)\n",
       "LGL              0.701 (0.859)   0.55 (0.654)  0.609 (0.734)   0.55 (0.668)\n",
       "TR-News          0.823 (0.929)   0.661 (0.73)  0.729 (0.814)  0.661 (0.746)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.concat([dataset_metrics_f, dataset_metrics_s], axis=1)\n",
    "\n",
    "tmp['avg_precision'] = tmp['precision_s'].astype(str) + ' (' + tmp['precision'].astype(str) + ')' \n",
    "\n",
    "tmp['avg_recall'] = tmp['recall_s'].astype(str) + ' (' + tmp['recall'].astype(str) + ')' \n",
    "\n",
    "tmp['avg_f1'] = tmp['f1_s'].astype(str) + ' (' + tmp['f1'].astype(str) + ')' \n",
    "\n",
    "tmp['avg_acc'] = tmp['acc_s'].astype(str) + ' (' + tmp['acc'].astype(str) + ')' \n",
    "\n",
    "tmp = tmp[['avg_precision', 'avg_recall', 'avg_f1', 'avg_acc']]\n",
    "tmp\n",
    "\n",
    "# tmp.to_excel('dataset-avg-metrics.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
